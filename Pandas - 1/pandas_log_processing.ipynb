{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c69a48",
   "metadata": {},
   "source": [
    "# Pandas Essentials and Real-world Log Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbfa45c",
   "metadata": {},
   "source": [
    "## Series & DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee73c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:\n",
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    6\n",
      "4    8\n",
      "dtype: int64\n",
      "\n",
      "DataFrame:\n",
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n",
      "\n",
      "DataFrame columns: ['A', 'B', 'C']\n",
      "DataFrame index: [0, 1, 2]\n",
      "DataFrame shape: (3, 3)\n",
      "\n",
      "Column A:\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "Name: A, dtype: int64\n",
      "\n",
      "First two rows:\n",
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a Series\n",
    "s = pd.Series([1, 3, 5, 6, 8])\n",
    "print(\"Series:\")\n",
    "print(s)\n",
    "print()\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# Basic operations\n",
    "print(\"DataFrame columns:\", df.columns.tolist())\n",
    "print(\"DataFrame index:\", df.index.tolist())\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "print()\n",
    "\n",
    "# Indexing and slicing\n",
    "print(\"Column A:\")\n",
    "print(df['A'])\n",
    "print()\n",
    "print(\"First two rows:\")\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57ccfe",
   "metadata": {},
   "source": [
    "## Reading CSV/JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b7ce1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from CSV:\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "\n",
      "Data from JSON:\n",
      "      name  age         city\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "# Reading CSV (assuming a sample CSV exists)\n",
    "# df_csv = pd.read_csv('sample.csv')\n",
    "# For demo, create sample data\n",
    "csv_data = \"\"\"Name,Age,City\n",
    "Alice,25,New York\n",
    "Bob,30,Los Angeles\n",
    "Charlie,35,Chicago\"\"\"\n",
    "with open('sample.csv', 'w') as f:\n",
    "    f.write(csv_data)\n",
    "\n",
    "df_csv = pd.read_csv('sample.csv')\n",
    "print(\"Data from CSV:\")\n",
    "print(df_csv)\n",
    "print()\n",
    "\n",
    "# Reading JSON\n",
    "json_data = \"\"\"[\n",
    "{\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n",
    "{\"name\": \"Bob\", \"age\": 30, \"city\": \"Los Angeles\"},\n",
    "{\"name\": \"Charlie\", \"age\": 35, \"city\": \"Chicago\"}\n",
    "]\"\"\"\n",
    "with open('sample.json', 'w') as f:\n",
    "    f.write(json_data)\n",
    "\n",
    "df_json = pd.read_json('sample.json')\n",
    "print(\"Data from JSON:\")\n",
    "print(df_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c8fd0",
   "metadata": {},
   "source": [
    "## Filtering rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5146b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "\n",
      "Filtered rows (Age > 25):\n",
      "      Name  Age         City\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "\n",
      "Filtered with query (Age > 25 and City == 'Chicago'):\n",
      "      Name  Age     City\n",
      "2  Charlie   35  Chicago\n"
     ]
    }
   ],
   "source": [
    "# Filtering rows\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_csv)\n",
    "print()\n",
    "\n",
    "# Filter rows where Age > 25\n",
    "filtered_df = df_csv[df_csv['Age'] > 25]\n",
    "print(\"Filtered rows (Age > 25):\")\n",
    "print(filtered_df)\n",
    "print()\n",
    "\n",
    "# Using query method\n",
    "filtered_query = df_csv.query('Age > 25 and City == \"Chicago\"')\n",
    "print(\"Filtered with query (Age > 25 and City == 'Chicago'):\")\n",
    "print(filtered_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec76e74",
   "metadata": {},
   "source": [
    "## Handling missing values (fillna, dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5581534a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with missing values:\n",
      "     A    B     C\n",
      "0  1.0  5.0   9.0\n",
      "1  2.0  NaN  10.0\n",
      "2  NaN  7.0  11.0\n",
      "3  4.0  8.0   NaN\n",
      "\n",
      "Is null:\n",
      "       A      B      C\n",
      "0  False  False  False\n",
      "1  False   True  False\n",
      "2   True  False  False\n",
      "3  False  False   True\n",
      "\n",
      "After dropna():\n",
      "     A    B    C\n",
      "0  1.0  5.0  9.0\n",
      "\n",
      "After fillna(0):\n",
      "     A    B     C\n",
      "0  1.0  5.0   9.0\n",
      "1  2.0  0.0  10.0\n",
      "2  0.0  7.0  11.0\n",
      "3  4.0  8.0   0.0\n",
      "\n",
      "After fillna with mean:\n",
      "          A         B     C\n",
      "0  1.000000  5.000000   9.0\n",
      "1  2.000000  6.666667  10.0\n",
      "2  2.333333  7.000000  11.0\n",
      "3  4.000000  8.000000  10.0\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "df_missing = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': [5, np.nan, 7, 8],\n",
    "    'C': [9, 10, 11, np.nan]\n",
    "})\n",
    "print(\"DataFrame with missing values:\")\n",
    "print(df_missing)\n",
    "print()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Is null:\")\n",
    "print(df_missing.isnull())\n",
    "print()\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropped = df_missing.dropna()\n",
    "print(\"After dropna():\")\n",
    "print(df_dropped)\n",
    "print()\n",
    "\n",
    "# Fill missing values\n",
    "df_filled = df_missing.fillna(0)\n",
    "print(\"After fillna(0):\")\n",
    "print(df_filled)\n",
    "print()\n",
    "\n",
    "# Fill with mean\n",
    "df_filled_mean = df_missing.fillna(df_missing.mean())\n",
    "print(\"After fillna with mean:\")\n",
    "print(df_filled_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ab11a",
   "metadata": {},
   "source": [
    "## Sorting, merging, grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aabfef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "\n",
      "Sorted by Age:\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "\n",
      "Merged DataFrames:\n",
      "  key  value1  value2\n",
      "0   A     1.0     4.0\n",
      "1   B     2.0     5.0\n",
      "2   C     3.0     NaN\n",
      "3   D     NaN     6.0\n",
      "\n",
      "Grouped by City, mean Age:\n",
      "City\n",
      "Chicago        35.0\n",
      "Los Angeles    30.0\n",
      "New York       25.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sorting\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_csv)\n",
    "print()\n",
    "\n",
    "# Sort by Age\n",
    "sorted_df = df_csv.sort_values('Age')\n",
    "print(\"Sorted by Age:\")\n",
    "print(sorted_df)\n",
    "print()\n",
    "\n",
    "# Merging\n",
    "df1 = pd.DataFrame({\n",
    "    'key': ['A', 'B', 'C'], \n",
    "    'value1': [1, 2, 3]\n",
    "    })\n",
    "\n",
    "df2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'value2': [4, 5, 6]})\n",
    "merged_df = pd.merge(df1, df2, on='key', how='outer')\n",
    "\n",
    "print(\"Merged DataFrames:\")\n",
    "print(merged_df)\n",
    "print()\n",
    "\n",
    "# Grouping\n",
    "grouped = df_csv.groupby('City')['Age'].mean()\n",
    "print(\"Grouped by City, mean Age:\")\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1930638",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "389bfa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for aggregation:\n",
      "  Category  Value\n",
      "0        A     10\n",
      "1        A     20\n",
      "2        B     30\n",
      "3        B     40\n",
      "4        C     50\n",
      "\n",
      "Aggregated:\n",
      "         Value            \n",
      "           sum  mean count\n",
      "Category                  \n",
      "A           30  15.0     2\n",
      "B           70  35.0     2\n",
      "C           50  50.0     1\n",
      "\n",
      "Pivot table:\n",
      "           sum  mean\n",
      "         Value Value\n",
      "Category            \n",
      "A           30  15.0\n",
      "B           70  35.0\n",
      "C           50  50.0\n"
     ]
    }
   ],
   "source": [
    "# Aggregation\n",
    "df_agg = pd.DataFrame({\n",
    "    'Category': ['A', 'A', 'B', 'B', 'C'],\n",
    "    'Value': [10, 20, 30, 40, 50]\n",
    "})\n",
    "print(\"DataFrame for aggregation:\")\n",
    "print(df_agg)\n",
    "print()\n",
    "\n",
    "# Group and aggregate\n",
    "grouped_agg = df_agg.groupby('Category').agg({\n",
    "    'Value': ['sum', 'mean', 'count']\n",
    "})\n",
    "print(\"Aggregated:\")\n",
    "print(grouped_agg)\n",
    "print()\n",
    "\n",
    "# Pivot table\n",
    "pivot = df_agg.pivot_table(values='Value', index='Category', aggfunc=['sum', 'mean'])\n",
    "print(\"Pivot table:\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a82ca7",
   "metadata": {},
   "source": [
    "## Working with datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2685b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with date strings:\n",
      "     date_str  value\n",
      "0  2023-01-01      1\n",
      "1  2023-02-01      2\n",
      "2  2023-03-01      3\n",
      "\n",
      "After converting to datetime:\n",
      "     date_str  value       date\n",
      "0  2023-01-01      1 2023-01-01\n",
      "1  2023-02-01      2 2023-02-01\n",
      "2  2023-03-01      3 2023-03-01\n",
      "\n",
      "With extracted year and month:\n",
      "     date_str  value       date  year  month\n",
      "0  2023-01-01      1 2023-01-01  2023      1\n",
      "1  2023-02-01      2 2023-02-01  2023      2\n",
      "2  2023-03-01      3 2023-03-01  2023      3\n",
      "\n",
      "Filtered dates after 2023-01-15:\n",
      "     date_str  value       date  year  month\n",
      "1  2023-02-01      2 2023-02-01  2023      2\n",
      "2  2023-03-01      3 2023-03-01  2023      3\n"
     ]
    }
   ],
   "source": [
    "# Working with datetime\n",
    "df_datetime = pd.DataFrame({\n",
    "    'date_str': ['2023-01-01', '2023-02-01', '2023-03-01'],\n",
    "    'value': [1, 2, 3]\n",
    "})\n",
    "print(\"DataFrame with date strings:\")\n",
    "print(df_datetime)\n",
    "print()\n",
    "\n",
    "# Convert to datetime\n",
    "df_datetime['date'] = pd.to_datetime(df_datetime['date_str'])\n",
    "print(\"After converting to datetime:\")\n",
    "print(df_datetime)\n",
    "print()\n",
    "\n",
    "# Extract components\n",
    "df_datetime['year'] = df_datetime['date'].dt.year\n",
    "df_datetime['month'] = df_datetime['date'].dt.month\n",
    "print(\"With extracted year and month:\")\n",
    "print(df_datetime)\n",
    "print()\n",
    "\n",
    "# Date-based filtering\n",
    "filtered_dates = df_datetime[df_datetime['date'] > '2023-01-15']\n",
    "print(\"Filtered dates after 2023-01-15:\")\n",
    "print(filtered_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184f192",
   "metadata": {},
   "source": [
    "## Load API logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdf7891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API logs:\n",
      "           timestamp           ip method     endpoint  status  response_time\n",
      "2023-01-01  10:00:00  192.168.1.1    GET   /api/users     200            150\n",
      "2023-01-01  10:01:00  192.168.1.2   POST   /api/login     201            200\n",
      "2023-01-01  10:02:00  192.168.1.1    GET    /api/data     404             50\n",
      "2023-01-01  10:03:00  192.168.1.3    PUT  /api/update     200            300\n",
      "2023-01-01  10:04:00  192.168.1.2    GET   /api/users     200            120\n"
     ]
    }
   ],
   "source": [
    "# Load API logs\n",
    "# Sample log data\n",
    "log_data = \"\"\"2023-01-01 10:00:00 192.168.1.1 GET /api/users 200 150\n",
    "2023-01-01 10:01:00 192.168.1.2 POST /api/login 201 200\n",
    "2023-01-01 10:02:00 192.168.1.1 GET /api/data 404 50\n",
    "2023-01-01 10:03:00 192.168.1.3 PUT /api/update 200 300\n",
    "2023-01-01 10:04:00 192.168.1.2 GET /api/users 200 120\"\"\"\n",
    "\n",
    "with open('api_logs.txt', 'w') as f:\n",
    "    f.write(log_data)\n",
    "\n",
    "# Load into DataFrame\n",
    "logs_df = pd.read_csv('api_logs.txt', sep=' ', header=None, \n",
    "                      names=['timestamp', 'ip', 'method', 'endpoint', 'status', 'response_time'])\n",
    "print(\"Loaded API logs:\")\n",
    "print(logs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950ad9d",
   "metadata": {},
   "source": [
    "## Clean logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e45f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original logs:\n",
      "           timestamp           ip method     endpoint  status  response_time\n",
      "2023-01-01  10:00:00  192.168.1.1    GET   /api/users     200            150\n",
      "2023-01-01  10:01:00  192.168.1.2   POST   /api/login     201            200\n",
      "2023-01-01  10:02:00  192.168.1.1    GET    /api/data     404             50\n",
      "2023-01-01  10:03:00  192.168.1.3    PUT  /api/update     200            300\n",
      "2023-01-01  10:04:00  192.168.1.2    GET   /api/users     200            120\n",
      "\n",
      "Cleaned logs:\n",
      "                     timestamp           ip method     endpoint  status  \\\n",
      "2023-01-01 2026-01-03 10:00:00  192.168.1.1    GET   /api/users     200   \n",
      "2023-01-01 2026-01-03 10:01:00  192.168.1.2   POST   /api/login     201   \n",
      "2023-01-01 2026-01-03 10:02:00  192.168.1.1    GET    /api/data     404   \n",
      "2023-01-01 2026-01-03 10:03:00  192.168.1.3    PUT  /api/update     200   \n",
      "2023-01-01 2026-01-03 10:04:00  192.168.1.2    GET   /api/users     200   \n",
      "\n",
      "            response_time  \n",
      "2023-01-01            150  \n",
      "2023-01-01            200  \n",
      "2023-01-01             50  \n",
      "2023-01-01            300  \n",
      "2023-01-01            120  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag\\AppData\\Local\\Temp\\ipykernel_4984\\3880420612.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  logs_df['timestamp'] = pd.to_datetime(logs_df['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "# Clean logs\n",
    "print(\"Original logs:\")\n",
    "print(logs_df)\n",
    "print()\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "logs_df['timestamp'] = pd.to_datetime(logs_df['timestamp'])\n",
    "\n",
    "# Remove duplicates if any\n",
    "logs_df_clean = logs_df.drop_duplicates()\n",
    "\n",
    "# Standardize formats (assuming no inconsistencies in sample)\n",
    "print(\"Cleaned logs:\")\n",
    "print(logs_df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf3e160",
   "metadata": {},
   "source": [
    "## Extract IP, endpoint, response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c63ec8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPs:\n",
      "2023-01-01    192.168.1.1\n",
      "2023-01-01    192.168.1.2\n",
      "2023-01-01    192.168.1.1\n",
      "2023-01-01    192.168.1.3\n",
      "2023-01-01    192.168.1.2\n",
      "Name: ip, dtype: object\n",
      "\n",
      "Endpoints:\n",
      "2023-01-01     /api/users\n",
      "2023-01-01     /api/login\n",
      "2023-01-01      /api/data\n",
      "2023-01-01    /api/update\n",
      "2023-01-01     /api/users\n",
      "Name: endpoint, dtype: object\n",
      "\n",
      "Response times:\n",
      "2023-01-01    150\n",
      "2023-01-01    200\n",
      "2023-01-01     50\n",
      "2023-01-01    300\n",
      "2023-01-01    120\n",
      "Name: response_time, dtype: int64\n",
      "\n",
      "Endpoint bases:\n",
      "2023-01-01     users\n",
      "2023-01-01     login\n",
      "2023-01-01      data\n",
      "2023-01-01    update\n",
      "2023-01-01     users\n",
      "Name: endpoint_base, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract IP, endpoint, response time\n",
    "# IP is already extracted\n",
    "print(\"IPs:\")\n",
    "print(logs_df_clean['ip'])\n",
    "print()\n",
    "\n",
    "# Endpoint is already extracted\n",
    "print(\"Endpoints:\")\n",
    "print(logs_df_clean['endpoint'])\n",
    "print()\n",
    "\n",
    "# Response time is already extracted\n",
    "print(\"Response times:\")\n",
    "print(logs_df_clean['response_time'])\n",
    "print()\n",
    "\n",
    "# Extract additional info, e.g., endpoint base\n",
    "logs_df_clean['endpoint_base'] = logs_df_clean['endpoint'].str.split('/').str[2]\n",
    "print(\"Endpoint bases:\")\n",
    "print(logs_df_clean['endpoint_base'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6508d",
   "metadata": {},
   "source": [
    "## Calculate average latency & throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44069360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency: 164.0 ms\n",
      "\n",
      "Throughput: 1.25 requests per minute\n",
      "Endpoint statistics:\n",
      "              mean  count\n",
      "endpoint                 \n",
      "/api/data     50.0      1\n",
      "/api/login   200.0      1\n",
      "/api/update  300.0      1\n",
      "/api/users   135.0      2\n"
     ]
    }
   ],
   "source": [
    "# Calculate average latency & throughput\n",
    "# Average latency (response time)\n",
    "avg_latency = logs_df_clean['response_time'].mean()\n",
    "print(f\"Average latency: {avg_latency} ms\")\n",
    "print()\n",
    "\n",
    "# Throughput: requests per minute (assuming logs are over a period)\n",
    "# For demo, calculate total requests and assume time span\n",
    "time_span_minutes = (logs_df_clean['timestamp'].max() - logs_df_clean['timestamp'].min()).total_seconds() / 60\n",
    "if time_span_minutes > 0:\n",
    "    throughput = len(logs_df_clean) / time_span_minutes\n",
    "    print(f\"Throughput: {throughput} requests per minute\")\n",
    "else:\n",
    "    print(\"Throughput: Cannot calculate (same timestamp)\")\n",
    "\n",
    "# Group by endpoint\n",
    "endpoint_stats = logs_df_clean.groupby('endpoint')['response_time'].agg(['mean', 'count'])\n",
    "print(\"Endpoint statistics:\")\n",
    "print(endpoint_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
